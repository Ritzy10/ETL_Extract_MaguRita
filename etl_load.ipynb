{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5619842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "data_dir = Path('.')\n",
    "output_dir = Path('loaded_data')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "full_csv_path = data_dir / 'transformed_full.csv'\n",
    "incremental_csv_path = data_dir / 'transformed_incremental.csv'\n",
    "\n",
    "sqlite_full_path = output_dir / 'full_data.db'\n",
    "sqlite_incremental_path = output_dir / 'incremental_data.db'\n",
    "parquet_full_path = output_dir / 'full_data.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601d9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full transformed data from CSV\n",
    "df_full = pd.read_csv(full_csv_path)\n",
    "\n",
    "# Save to SQLite database\n",
    "conn_full = sqlite3.connect(sqlite_full_path)\n",
    "df_full.to_sql('full_data', conn_full, if_exists='replace', index=False)\n",
    "conn_full.close()\n",
    "\n",
    "# Save full data as Parquet file\n",
    "df_full.to_parquet(parquet_full_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5639d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load incremental transformed data\n",
    "df_incremental = pd.read_csv(incremental_csv_path)\n",
    "\n",
    "# Save to SQLite database\n",
    "conn_incremental = sqlite3.connect(sqlite_incremental_path)\n",
    "df_incremental.to_sql('incremental_data', conn_incremental, if_exists='replace', index=False)\n",
    "conn_incremental.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899d67c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data (SQLite):\n",
      "     id customer        date  amount         last_updated  amount_with_tax  \\\n",
      "0  3636  Walmart  2025-04-02    1386  2025-04-02 22:55:00          1607.76   \n",
      "1  2615  Walmart  2025-04-02     925  2025-04-02 01:48:00          1073.00   \n",
      "2  6180   Amazon  2025-04-02    1950  2025-04-02 01:35:00          2262.00   \n",
      "3  7060  BestBuy  2025-04-02     355  2025-04-02 13:22:00           411.80   \n",
      "4  8236   Costco  2025-04-02     581  2025-04-02 10:29:00           673.96   \n",
      "\n",
      "  amount_category  \n",
      "0            High  \n",
      "1          Medium  \n",
      "2       Very High  \n",
      "3             Low  \n",
      "4          Medium  \n"
     ]
    }
   ],
   "source": [
    "# Read from SQLite to verify full_data\n",
    "print(\"Full Data (SQLite):\")\n",
    "conn = sqlite3.connect(sqlite_full_path)\n",
    "print(pd.read_sql(\"SELECT * FROM full_data LIMIT 5;\", conn))\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b03b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Data (Parquet):\n",
      "     id customer        date  amount         last_updated  amount_with_tax  \\\n",
      "0  3636  Walmart  2025-04-02    1386  2025-04-02 22:55:00          1607.76   \n",
      "1  2615  Walmart  2025-04-02     925  2025-04-02 01:48:00          1073.00   \n",
      "2  6180   Amazon  2025-04-02    1950  2025-04-02 01:35:00          2262.00   \n",
      "3  7060  BestBuy  2025-04-02     355  2025-04-02 13:22:00           411.80   \n",
      "4  8236   Costco  2025-04-02     581  2025-04-02 10:29:00           673.96   \n",
      "\n",
      "  amount_category  \n",
      "0            High  \n",
      "1          Medium  \n",
      "2       Very High  \n",
      "3             Low  \n",
      "4          Medium  \n"
     ]
    }
   ],
   "source": [
    "# Check and preview the Parquet file\n",
    "print(\"\\nFull Data (Parquet):\")\n",
    "if parquet_full_path.exists():\n",
    "    df_parquet = pd.read_parquet(parquet_full_path)\n",
    "    print(df_parquet.head())\n",
    "else:\n",
    "    print(\"Parquet file does not exist. Please generate it first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
